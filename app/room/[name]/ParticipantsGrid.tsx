'use client'
import { useEffect, useState, useRef } from 'react'
import { LocalParticipant, RemoteParticipant, Track } from 'livekit-client'

interface ParticipantsGridProps {
  participants: (LocalParticipant | RemoteParticipant)[]
}

export default function ParticipantsGrid({ participants }: ParticipantsGridProps) {
  return (
    <div style={{
      display: 'grid',
      gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))',
      gap: '10px',
      padding: '1rem',
      height: '100%',
      overflow: 'auto'
    }}>
      {participants.map((participant) => (
        <ParticipantVideo key={participant.identity} participant={participant} />
      ))}
    </div>
  )
}

function ParticipantVideo({ participant }: { participant: LocalParticipant | RemoteParticipant }) {
  const [remoteVideoElement, setRemoteVideoElement] = useState<HTMLVideoElement | null>(null)
  const [remoteScreenElement, setRemoteScreenElement] = useState<HTMLVideoElement | null>(null)
  const [localCameraStream, setLocalCameraStream] = useState<MediaStream | null>(null)
  const [localScreenStream, setLocalScreenStream] = useState<MediaStream | null>(null)
  const [hasRemoteCamera, setHasRemoteCamera] = useState(false)
  const [hasRemoteScreen, setHasRemoteScreen] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  
  const isLocal = participant instanceof LocalParticipant

  // –ü–æ–ª—É—á–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∏–º—ã –ø—Ä—è–º–æ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
  useEffect(() => {
    if (!isLocal) return

    let cameraStream: MediaStream | null = null
    let screenStream: MediaStream | null = null

    const getLocalStreams = async () => {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ —Ç—Ä–µ–∫–∏ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω—ã –≤ LiveKit
      const cameraTrack = participant.getTrackPublication(Track.Source.Camera)?.track
      const screenTrack = participant.getTrackPublication(Track.Source.ScreenShare)?.track

      console.log(`üè† –õ–æ–∫–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–∫–∏: –∫–∞–º–µ—Ä–∞=${!!cameraTrack}, —ç–∫—Ä–∞–Ω=${!!screenTrack}`)

      // –ï—Å–ª–∏ –µ—Å—Ç—å —Ç—Ä–µ–∫ –∫–∞–º–µ—Ä—ã –≤ LiveKit, –ø–æ–ª—É—á–∞–µ–º –∫–∞–º–µ—Ä—É –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
      if (cameraTrack && !localCameraStream) {
        try {
          cameraStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false })
          setLocalCameraStream(cameraStream)
          console.log(`‚úÖ –ü–æ–ª—É—á–µ–Ω –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ –∫–∞–º–µ—Ä—ã`)
        } catch (error) {
          console.error(`‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã:`, error)
        }
      } else if (!cameraTrack && localCameraStream) {
        localCameraStream.getTracks().forEach(track => track.stop())
        setLocalCameraStream(null)
      }

      // –ï—Å–ª–∏ –µ—Å—Ç—å —Ç—Ä–µ–∫ —ç–∫—Ä–∞–Ω–∞ –≤ LiveKit, –ø–æ–ª—É—á–∞–µ–º —ç–∫—Ä–∞–Ω –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞
      if (screenTrack && !localScreenStream) {
        try {
          screenStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: false })
          setLocalScreenStream(screenStream)
          console.log(`‚úÖ –ü–æ–ª—É—á–µ–Ω –ª–æ–∫–∞–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ —ç–∫—Ä–∞–Ω–∞`)
        } catch (error) {
          console.error(`‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–∫—Ä–∞–Ω–∞:`, error)
        }
      } else if (!screenTrack && localScreenStream) {
        localScreenStream.getTracks().forEach(track => track.stop())
        setLocalScreenStream(null)
      }
    }

    getLocalStreams()

    // –°–ª—É—à–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç—Ä–µ–∫–æ–≤
    const events = ['localTrackPublished', 'localTrackUnpublished']
    events.forEach(event => {
      participant.on(event as any, getLocalStreams)
    })

    const interval = setInterval(getLocalStreams, 3000)

    return () => {
      events.forEach(event => {
        participant.off(event as any, getLocalStreams)
      })
      clearInterval(interval)
      
      if (cameraStream) {
        cameraStream.getTracks().forEach(track => track.stop())
      }
      if (screenStream) {
        screenStream.getTracks().forEach(track => track.stop())
      }
    }
  }, [participant, isLocal, localCameraStream, localScreenStream])

  // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —É–¥–∞–ª—ë–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏
  useEffect(() => {
    if (isLocal) return

    const updateRemoteTracks = () => {
      // –ö–∞–º–µ—Ä–∞
      const cameraPublication = participant.getTrackPublication(Track.Source.Camera)
      const cameraTrack = cameraPublication?.track
      
      if (cameraTrack && !remoteVideoElement) {
        const video = document.createElement('video')
        video.autoplay = true
        video.playsInline = true
        video.muted = false
        video.style.width = '100%'
        video.style.height = '100%'
        video.style.objectFit = 'cover'

        try {
          cameraTrack.attach(video)
          setRemoteVideoElement(video)
          setHasRemoteCamera(true)
          console.log(`‚úÖ –£–¥–∞–ª—ë–Ω–Ω–∞—è –∫–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ –¥–ª—è ${participant.name}`)
        } catch (error) {
          console.error(`‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —É–¥–∞–ª—ë–Ω–Ω–æ–π –∫–∞–º–µ—Ä—ã:`, error)
        }
      } else if (!cameraTrack) {
        setHasRemoteCamera(false)
        setRemoteVideoElement(null)
      }

      // –≠–∫—Ä–∞–Ω
      const screenPublication = participant.getTrackPublication(Track.Source.ScreenShare)
      const screenTrack = screenPublication?.track
      
      if (screenTrack && !remoteScreenElement) {
        const video = document.createElement('video')
        video.autoplay = true
        video.playsInline = true
        video.muted = false
        video.style.width = '100%'
        video.style.height = '100%'
        video.style.objectFit = 'contain'

        try {
          screenTrack.attach(video)
          setRemoteScreenElement(video)
          setHasRemoteScreen(true)
          console.log(`‚úÖ –£–¥–∞–ª—ë–Ω–Ω—ã–π —ç–∫—Ä–∞–Ω –ø–æ–¥–∫–ª—é—á–µ–Ω –¥–ª—è ${participant.name}`)
        } catch (error) {
          console.error(`‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ —ç–∫—Ä–∞–Ω–∞:`, error)
        }
      } else if (!screenTrack) {
        setHasRemoteScreen(false)
        setRemoteScreenElement(null)
      }

      // –ê—É–¥–∏–æ
      const audioPublication = participant.getTrackPublication(Track.Source.Microphone)
      setIsSpeaking(!!audioPublication?.track && !audioPublication.isMuted)
    }

    updateRemoteTracks()

    const events = ['trackPublished', 'trackUnpublished', 'trackSubscribed', 'trackUnsubscribed']
    events.forEach(event => {
      participant.on(event as any, updateRemoteTracks)
    })

    const interval = setInterval(updateRemoteTracks, 2000)

    return () => {
      events.forEach(event => {
        participant.off(event as any, updateRemoteTracks)
      })
      clearInterval(interval)
    }
  }, [participant, isLocal, remoteVideoElement, remoteScreenElement])

  const tiles = []

  // –¢–∞–π–ª –∫–∞–º–µ—Ä—ã
  if (isLocal) {
    // –õ–æ–∫–∞–ª—å–Ω–∞—è –∫–∞–º–µ—Ä–∞
    tiles.push(
      <LocalVideoTile
        key="local-camera"
        stream={localCameraStream}
        participant={participant}
        type="camera"
        isSpeaking={isSpeaking}
      />
    )
    // –õ–æ–∫–∞–ª—å–Ω—ã–π —ç–∫—Ä–∞–Ω
    if (localScreenStream) {
      tiles.push(
        <LocalVideoTile
          key="local-screen"
          stream={localScreenStream}
          participant={participant}
          type="screen"
          isSpeaking={false}
        />
      )
    }
  } else {
    // –£–¥–∞–ª—ë–Ω–Ω–∞—è –∫–∞–º–µ—Ä–∞
    tiles.push(
      <RemoteVideoTile
        key="remote-camera"
        videoElement={remoteVideoElement}
        hasVideo={hasRemoteCamera}
        participant={participant}
        type="camera"
        isSpeaking={isSpeaking}
      />
    )
    // –£–¥–∞–ª—ë–Ω–Ω—ã–π —ç–∫—Ä–∞–Ω
    if (hasRemoteScreen && remoteScreenElement) {
      tiles.push(
        <RemoteVideoTile
          key="remote-screen"
          videoElement={remoteScreenElement}
          hasVideo={hasRemoteScreen}
          participant={participant}
          type="screen"
          isSpeaking={false}
        />
      )
    }
  }

  return <>{tiles}</>
}

function LocalVideoTile({ 
  stream, 
  participant, 
  type, 
  isSpeaking 
}: {
  stream: MediaStream | null
  participant: LocalParticipant
  type: 'camera' | 'screen'
  isSpeaking: boolean
}) {
  const videoRef = useRef<HTMLVideoElement>(null)

  useEffect(() => {
    if (videoRef.current && stream) {
      videoRef.current.srcObject = stream
      console.log(`üì∫ –õ–æ–∫–∞–ª—å–Ω—ã–π ${type} –ø–æ—Ç–æ–∫ –ø–æ–¥–∫–ª—é—á–µ–Ω –∫ –≤–∏–¥–µ–æ —ç–ª–µ–º–µ–Ω—Ç—É`)
    }
  }, [stream, type])

  const borderColor = isSpeaking && type === 'camera' ? '#00ff00' : 'transparent'

  return (
    <div style={{
      background: type === 'screen' ? '#000' : '#222',
      borderRadius: '8px',
      overflow: 'hidden',
      position: 'relative',
      minHeight: type === 'screen' ? '300px' : '200px',
      display: 'flex',
      alignItems: 'center',
      justifyContent: 'center',
      border: `2px solid ${borderColor}`,
      transition: 'border 0.3s ease',
      marginBottom: '10px'
    }}>
      {stream ? (
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted={true}
          style={{ 
            width: '100%', 
            height: '100%', 
            objectFit: type === 'screen' ? 'contain' : 'cover' 
          }}
        />
      ) : (
        type === 'camera' && (
          <div style={{
            width: '80px',
            height: '80px',
            borderRadius: '50%',
            background: isSpeaking ? '#00aa00' : '#007acc',
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center',
            fontSize: '2rem',
            color: 'white'
          }}>
            {participant.name?.charAt(0).toUpperCase() || 'U'}
          </div>
        )
      )}
      
      <div style={{
        position: 'absolute',
        bottom: '8px',
        left: '8px',
        background: 'rgba(0,0,0,0.8)',
        color: 'white',
        padding: '4px 8px',
        borderRadius: '4px',
        fontSize: '0.8rem'
      }}>
        {participant.name || participant.identity}
        {type === 'screen' && ' (—ç–∫—Ä–∞–Ω)'}
        {' (–≤—ã)'}
        {isSpeaking && type === 'camera' && ' üé§'}
      </div>
    </div>
  )
}

function RemoteVideoTile({ 
  videoElement, 
  hasVideo, 
  participant, 
  type, 
  isSpeaking 
}: {
  videoElement: HTMLVideoElement | null
  hasVideo: boolean
  participant: RemoteParticipant
  type: 'camera' | 'screen'
  isSpeaking: boolean
}) {
  const containerRef = useRef<HTMLDivElement>(null)

  useEffect(() => {
    if (containerRef.current && videoElement && hasVideo) {
      containerRef.current.innerHTML = ''
      containerRef.current.appendChild(videoElement)
    }
  }, [videoElement, hasVideo])

  const borderColor = isSpeaking && type === 'camera' ? '#00ff00' : 'transparent'

  return (
    <div style={{
      background: type === 'screen' ? '#000' : '#222',
      borderRadius: '8px',
      overflow: 'hidden',
      position: 'relative',
      minHeight: type === 'screen' ? '300px' : '200px',
      display: 'flex',
      alignItems: 'center',
      justifyContent: 'center',
      border: `2px solid ${borderColor}`,
      transition: 'border 0.3s ease',
      marginBottom: '10px'
    }}>
      <div ref={containerRef} style={{ width: '100%', height: '100%' }}>
        {!hasVideo && type === 'camera' && (
          <div style={{
            width: '100%',
            height: '100%',
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center'
          }}>
            <div style={{
              width: '80px',
              height: '80px',
              borderRadius: '50%',
              background: isSpeaking ? '#00aa00' : '#007acc',
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center',
              fontSize: '2rem',
              color: 'white'
            }}>
              {participant.name?.charAt(0).toUpperCase() || 'U'}
            </div>
          </div>
        )}
      </div>
      
      <div style={{
        position: 'absolute',
        bottom: '8px',
        left: '8px',
        background: 'rgba(0,0,0,0.8)',
        color: 'white',
        padding: '4px 8px',
        borderRadius: '4px',
        fontSize: '0.8rem'
      }}>
        {participant.name || participant.identity}
        {type === 'screen' && ' (—ç–∫—Ä–∞–Ω)'}
        {isSpeaking && type === 'camera' && ' üé§'}
      </div>
    </div>
  )
}

'use client'
import { useEffect, useState } from 'react'
import { LocalParticipant, RemoteParticipant, Track } from 'livekit-client'

interface ParticipantsGridProps {
  participants: (LocalParticipant | RemoteParticipant)[]
}

export default function ParticipantsGrid({ participants }: ParticipantsGridProps) {
  return (
    <div style={{
      display: 'grid',
      gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))',
      gap: '10px',
      padding: '1rem',
      height: '100%',
      overflow: 'auto'
    }}>
      {participants.map((participant) => (
        <ParticipantVideo key={participant.identity} participant={participant} />
      ))}
    </div>
  )
}

function ParticipantVideo({ participant }: { participant: LocalParticipant | RemoteParticipant }) {
  const [tiles, setTiles] = useState<JSX.Element[]>([])
  const [isSpeaking, setIsSpeaking] = useState(false)
  
  const isLocal = participant instanceof LocalParticipant

  useEffect(() => {
    console.log(`üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–∞ ${participant.name} (${isLocal ? '–ª–æ–∫–∞–ª—å–Ω—ã–π' : '—É–¥–∞–ª—ë–Ω–Ω—ã–π'})`)

    const updateParticipant = async () => {
      const newTiles: JSX.Element[] = []

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—É–¥–∏–æ
      const audioPublication = participant.getTrackPublication(Track.Source.Microphone)
      const speaking = !!audioPublication?.track && !audioPublication.isMuted
      setIsSpeaking(speaking)

      if (isLocal) {
        // –õ–æ–∫–∞–ª—å–Ω—ã–π —É—á–∞—Å—Ç–Ω–∏–∫
        const cameraTrack = participant.getTrackPublication(Track.Source.Camera)?.track
        const screenTrack = participant.getTrackPublication(Track.Source.ScreenShare)?.track

        console.log(`üè† –õ–æ–∫–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–∫–∏: –∫–∞–º–µ—Ä–∞=${!!cameraTrack}, —ç–∫—Ä–∞–Ω=${!!screenTrack}`)

        // –ö–∞–º–µ—Ä–∞
        if (cameraTrack) {
          try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false })
            newTiles.push(
              <LocalVideoTile 
                key="local-camera"
                stream={stream}
                participant={participant}
                type="camera"
                isSpeaking={speaking}
              />
            )
            console.log(`‚úÖ –õ–æ–∫–∞–ª—å–Ω–∞—è –∫–∞–º–µ—Ä–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞`)
          } catch (error) {
            console.error(`‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã:`, error)
            // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∞–≤–∞—Ç–∞—Ä
            newTiles.push(
              <AvatarTile 
                key="local-camera-avatar"
                participant={participant}
                isSpeaking={speaking}
              />
            )
          }
        } else {
          // –ê–≤–∞—Ç–∞—Ä –µ—Å–ª–∏ –Ω–µ—Ç –∫–∞–º–µ—Ä—ã
          newTiles.push(
            <AvatarTile 
              key="local-avatar"
              participant={participant}
              isSpeaking={speaking}
            />
          )
        }

        // –≠–∫—Ä–∞–Ω
        if (screenTrack) {
          try {
            const stream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: false })
            newTiles.push(
              <LocalVideoTile 
                key="local-screen"
                stream={stream}
                participant={participant}
                type="screen"
                isSpeaking={false}
              />
            )
            console.log(`‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π —ç–∫—Ä–∞–Ω –¥–æ–±–∞–≤–ª–µ–Ω`)
          } catch (error) {
            console.error(`‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–∫—Ä–∞–Ω–∞:`, error)
          }
        }

      } else {
        // –£–¥–∞–ª—ë–Ω–Ω—ã–π —É—á–∞—Å—Ç–Ω–∏–∫
        const cameraTrack = participant.getTrackPublication(Track.Source.Camera)?.track
        const screenTrack = participant.getTrackPublication(Track.Source.ScreenShare)?.track

        console.log(`üë• –£–¥–∞–ª—ë–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏: –∫–∞–º–µ—Ä–∞=${!!cameraTrack}, —ç–∫—Ä–∞–Ω=${!!screenTrack}`)

        // –ö–∞–º–µ—Ä–∞
        if (cameraTrack) {
          newTiles.push(
            <RemoteVideoTile 
              key="remote-camera"
              track={cameraTrack}
              participant={participant}
              type="camera"
              isSpeaking={speaking}
            />
          )
        } else {
          // –ê–≤–∞—Ç–∞—Ä –µ—Å–ª–∏ –Ω–µ—Ç –∫–∞–º–µ—Ä—ã
          newTiles.push(
            <AvatarTile 
              key="remote-avatar"
              participant={participant}
              isSpeaking={speaking}
            />
          )
        }

        // –≠–∫—Ä–∞–Ω
        if (screenTrack) {
          newTiles.push(
            <RemoteVideoTile 
              key="remote-screen"
              track={screenTrack}
              participant={participant}
              type="screen"
              isSpeaking={false}
            />
          )
        }
      }

      setTiles(newTiles)
    }

    updateParticipant()

    // –°–ª—É—à–∞–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    const events = [
      'trackPublished', 'trackUnpublished',
      'trackSubscribed', 'trackUnsubscribed',
      'localTrackPublished', 'localTrackUnpublished'
    ]
    events.forEach(event => {
      participant.on(event as any, updateParticipant)
    })

    const interval = setInterval(updateParticipant, 3000)

    return () => {
      events.forEach(event => {
        participant.off(event as any, updateParticipant)
      })
      clearInterval(interval)
    }
  }, [participant, isLocal])

  return <>{tiles}</>
}

function LocalVideoTile({ 
  stream, 
  participant, 
  type, 
  isSpeaking 
}: {
  stream: MediaStream
  participant: LocalParticipant
  type: 'camera' | 'screen'
  isSpeaking: boolean
}) {
  const [videoElement, setVideoElement] = useState<HTMLVideoElement | null>(null)

  useEffect(() => {
    console.log(`üì∫ –°–æ–∑–¥–∞—ë–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ ${type} –¥–ª—è ${participant.name}`)
    
    const video = document.createElement('video')
    video.autoplay = true
    video.playsInline = true
    video.muted = true
    video.style.width = '100%'
    video.style.height = '100%'
    video.style.objectFit = type === 'screen' ? 'contain' : 'cover'
    video.style.borderRadius = '8px'

    video.srcObject = stream
    
    video.onloadedmetadata = () => {
      console.log(`‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ ${type}`)
      video.play().catch(e => console.error('–û—à–∏–±–∫–∞ –∞–≤—Ç–æ–≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è:', e))
    }

    setVideoElement(video)

    return () => {
      stream.getTracks().forEach(track => track.stop())
      video.srcObject = null
    }
  }, [stream, participant.name, type])

  useEffect(() => {
    const container = document.getElementById(`local-${type}-${participant.identity}`)
    if (container && videoElement) {
      container.innerHTML = ''
      container.appendChild(videoElement)
      console.log(`üé¨ –õ–æ–∫–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ ${type} –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä`)
    }
  }, [videoElement, participant.identity, type])

  const borderColor = isSpeaking && type === 'camera' ? '#00ff00' : 'transparent'

  return (
    <div style={{
      background: type === 'screen' ? '#000' : '#222',
      borderRadius: '8px',
      overflow: 'hidden',
      position: 'relative',
      minHeight: type === 'screen' ? '300px' : '200px',
      border: `2px solid ${borderColor}`,
      transition: 'border 0.3s ease',
      marginBottom: '10px'
    }}>
      <div 
        id={`local-${type}-${participant.identity}`}
        style={{ width: '100%', height: '100%' }}
      />
      
      <div style={{
        position: 'absolute',
        bottom: '8px',
        left: '8px',
        background: 'rgba(0,0,0,0.8)',
        color: 'white',
        padding: '4px 8px',
        borderRadius: '4px',
        fontSize: '0.8rem'
      }}>
        {participant.name || participant.identity}
        {type === 'screen' && ' (—ç–∫—Ä–∞–Ω)'}
        {' (–≤—ã)'}
        {isSpeaking && type === 'camera' && ' üé§'}
      </div>
    </div>
  )
}

function RemoteVideoTile({ 
  track, 
  participant, 
  type, 
  isSpeaking 
}: {
  track: any
  participant: RemoteParticipant
  type: 'camera' | 'screen'
  isSpeaking: boolean
}) {
  const [videoElement, setVideoElement] = useState<HTMLVideoElement | null>(null)

  useEffect(() => {
    console.log(`üì∫ –°–æ–∑–¥–∞—ë–º —É–¥–∞–ª—ë–Ω–Ω–æ–µ –≤–∏–¥–µ–æ ${type} –¥–ª—è ${participant.name}`)
    
    const video = document.createElement('video')
    video.autoplay = true
    video.playsInline = true
    video.muted = false
    video.style.width = '100%'
    video.style.height = '100%'
    video.style.objectFit = type === 'screen' ? 'contain' : 'cover'

    try {
      track.attach(video)
      setVideoElement(video)
      console.log(`‚úÖ –£–¥–∞–ª—ë–Ω–Ω—ã–π ${type} —Ç—Ä–µ–∫ –ø–æ–¥–∫–ª—é—á—ë–Ω`)
    } catch (error) {
      console.error(`‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ ${type}:`, error)
    }

    return () => {
      if (video.parentNode) {
        video.parentNode.removeChild(video)
      }
    }
  }, [track, participant.name, type])

  useEffect(() => {
    const container = document.getElementById(`remote-${type}-${participant.identity}`)
    if (container && videoElement) {
      container.innerHTML = ''
      container.appendChild(videoElement)
      console.log(`üé¨ –£–¥–∞–ª—ë–Ω–Ω–æ–µ –≤–∏–¥–µ–æ ${type} –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä`)
    }
  }, [videoElement, participant.identity, type])

  const borderColor = isSpeaking && type === 'camera' ? '#00ff00' : 'transparent'

  return (
    <div style={{
      background: type === 'screen' ? '#000' : '#222',
      borderRadius: '8px',
      overflow: 'hidden',
      position: 'relative',
      minHeight: type === 'screen' ? '300px' : '200px',
      border: `2px solid ${borderColor}`,
      transition: 'border 0.3s ease',
      marginBottom: '10px'
    }}>
      <div 
        id={`remote-${type}-${participant.identity}`}
        style={{ width: '100%', height: '100%' }}
      />
      
      <div style={{
        position: 'absolute',
        bottom: '8px',
        left: '8px',
        background: 'rgba(0,0,0,0.8)',
        color: 'white',
        padding: '4px 8px',
        borderRadius: '4px',
        fontSize: '0.8rem'
      }}>
        {participant.name || participant.identity}
        {type === 'screen' && ' (—ç–∫—Ä–∞–Ω)'}
        {isSpeaking && type === 'camera' && ' üé§'}
      </div>
    </div>
  )
}

function AvatarTile({ participant, isSpeaking }: { 
  participant: LocalParticipant | RemoteParticipant
  isSpeaking: boolean 
}) {
  const isLocal = participant instanceof LocalParticipant
  const borderColor = isSpeaking ? '#00ff00' : 'transparent'

  return (
    <div style={{
      background: '#222',
      borderRadius: '8px',
      overflow: 'hidden',
      position: 'relative',
      minHeight: '200px',
      display: 'flex',
      alignItems: 'center',
      justifyContent: 'center',
      border: `2px solid ${borderColor}`,
      transition: 'border 0.3s ease',
      marginBottom: '10px'
    }}>
      <div style={{
        width: '80px',
        height: '80px',
        borderRadius: '50%',
        background: isSpeaking ? '#00aa00' : '#007acc',
        display: 'flex',
        alignItems: 'center',
        justifyContent: 'center',
        fontSize: '2rem',
        color: 'white',
        transition: 'background 0.3s ease'
      }}>
        {participant.name?.charAt(0).toUpperCase() || 'U'}
      </div>
      
      <div style={{
        position: 'absolute',
        bottom: '8px',
        left: '8px',
        background: 'rgba(0,0,0,0.8)',
        color: 'white',
        padding: '4px 8px',
        borderRadius: '4px',
        fontSize: '0.8rem'
      }}>
        {participant.name || participant.identity}
        {isLocal && ' (–≤—ã)'}
        {isSpeaking && ' üé§'}
      </div>
    </div>
  )
}

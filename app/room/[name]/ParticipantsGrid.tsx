'use client'
import { useEffect, useRef, useState } from 'react'
import { LocalParticipant, RemoteParticipant, Track, LocalVideoTrack } from 'livekit-client'

interface ParticipantsGridProps {
  participants: (LocalParticipant | RemoteParticipant)[]
}

export default function ParticipantsGrid({ participants }: ParticipantsGridProps) {
  const [allTiles, setAllTiles] = useState<JSX.Element[]>([])

  useEffect(() => {
    const tiles = []
    for (const participant of participants) {
      tiles.push(<ParticipantTile key={participant.identity + '-camera'} participant={participant} trackType="camera" />)
      
      // –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ç–∞–π–ª –¥–ª—è —ç–∫—Ä–∞–Ω—à–∞—Ä–∏–Ω–≥–∞, –µ—Å–ª–∏ –æ–Ω –≤–∫–ª—é—á—ë–Ω
      if (participant.getTrackPublication(Track.Source.ScreenShare)?.track) {
        tiles.push(<ParticipantTile key={participant.identity + '-screen'} participant={participant} trackType="screen" />)
      }
    }
    setAllTiles(tiles)
  }, [participants])

  return (
    <div style={{
      display: 'grid',
      gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))',
      gap: '10px',
      padding: '1rem',
      height: '100%',
      overflow: 'auto'
    }}>
      {allTiles}
    </div>
  )
}

function ParticipantTile({ participant, trackType }: { participant: LocalParticipant | RemoteParticipant; trackType: 'camera' | 'screen' }) {
  const videoRef = useRef<HTMLVideoElement>(null)
  const [hasTrack, setHasTrack] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const isLocal = participant instanceof LocalParticipant

  useEffect(() => {
    const source = trackType === 'camera' ? Track.Source.Camera : Track.Source.ScreenShare

    const updateTrack = () => {
      console.log(`–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∞ ${trackType} –¥–ª—è ${participant.name || participant.identity} (${isLocal ? '–ª–æ–∫–∞–ª—å–Ω—ã–π' : '—É–¥–∞–ª—ë–Ω–Ω—ã–π'})`)

      const publication = participant.getTrackPublication(source)
      const track = publication?.track as LocalVideoTrack | undefined

      if (track && videoRef.current) {
        console.log(`–ü–æ–¥–∫–ª—é—á–∞–µ–º ${trackType} –¥–ª—è ${participant.name || participant.identity}`)

        // –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        videoRef.current.srcObject = null

        if (isLocal) {
          // –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞ —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π MediaStream
          const mediaStreamTrack = track.mediaStreamTrack
          if (mediaStreamTrack) {
            const stream = new MediaStream([mediaStreamTrack])
            videoRef.current.srcObject = stream
            console.log(`–õ–æ–∫–∞–ª—å–Ω—ã–π ${trackType} –ø–æ–¥–∫–ª—é—á—ë–Ω —á–µ—Ä–µ–∑ MediaStream`)
          }
        } else {
          // –î–ª—è —É–¥–∞–ª—ë–Ω–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º attach
          track.attach(videoRef.current)
          console.log(`–£–¥–∞–ª—ë–Ω–Ω—ã–π ${trackType} –ø–æ–¥–∫–ª—é—á—ë–Ω —á–µ—Ä–µ–∑ attach`)
        }
        setHasTrack(true)
      } else {
        console.log(`–û—Ç–∫–ª—é—á–∞–µ–º ${trackType} –¥–ª—è ${participant.name || participant.identity}`)
        if (videoRef.current) {
          videoRef.current.srcObject = null
        }
        setHasTrack(false)
      }

      // –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ (—Ç–æ–ª—å–∫–æ –¥–ª—è –∫–∞–º–µ—Ä—ã-—Ç–∞–π–ª–∞)
      if (trackType === 'camera') {
        const audioPublication = participant.getTrackPublication(Track.Source.Microphone)
        const hasAudio = audioPublication?.track && !audioPublication.isMuted
        setIsSpeaking(hasAudio || false)
      }
    }

    // –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–∑—É
    updateTrack()

    // –°–ª—É—à–∞–µ–º —Å–æ–±—ã—Ç–∏—è
    const events = ['trackPublished', 'trackUnpublished', 'trackSubscribed', 'trackUnsubscribed', 'trackMuted', 'trackUnmuted', 'localTrackPublished', 'localTrackUnpublished']
    const listeners = events.map(event => {
      const listener = () => setTimeout(updateTrack, 100)
      participant.on(event as any, listener)
      return { event, listener }
    })

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 500–º—Å
    const interval = setInterval(updateTrack, 500)

    return () => {
      listeners.forEach(({ event, listener }) => participant.off(event as any, listener))
      clearInterval(interval)
      if (videoRef.current) {
        videoRef.current.srcObject = null
      }
    }
  }, [participant, isLocal, trackType])

  if (!hasTrack) return null

  const isScreen = trackType === 'screen'
  const title = isScreen ? '–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫—Ä–∞–Ω–∞' : '–∫–∞–º–µ—Ä–∞'
  const borderColor = isSpeaking && !isScreen ? '#00ff00' : 'transparent'
  const borderWidth = '2px'

  return (
    <div style={{
      background: '#000',
      borderRadius: '8px',
      overflow: 'hidden',
      position: 'relative',
      minHeight: '200px',
      border: `${borderWidth} solid ${borderColor}`,
      transition: 'border 0.3s ease'
    }}>
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted={isLocal || isSpeaking}  // –ú—å—é—Ç –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ, —á—Ç–æ–±—ã –Ω–µ —ç—Ö–æ
        style={{ width: '100%', height: '100%', objectFit: isScreen ? 'contain' : 'cover' }}
      />
      <div style={{
        position: 'absolute',
        bottom: '8px',
        left: '8px',
        background: 'rgba(0,0,0,0.8)',
        color: 'white',
        padding: '4px 8px',
        borderRadius: '4px',
        fontSize: '0.8rem'
      }}>
        {participant.name || participant.identity} ({title})
        {isLocal && ' (–≤—ã)'}
        {isSpeaking && !isScreen && ' üé§'}
      </div>
    </div>
  )
}

'use client'
import { useEffect, useRef, useState } from 'react'
import { LocalParticipant, RemoteParticipant, Track } from 'livekit-client'

interface ParticipantsGridProps {
  participants: (LocalParticipant | RemoteParticipant)[]
}

export default function ParticipantsGrid({ participants }: ParticipantsGridProps) {
  return (
    <div style={{
      display: 'grid',
      gridTemplateColumns: 'repeat(auto-fit, minmax(300px, 1fr))',
      gap: '10px',
      padding: '1rem',
      height: '100%',
      overflow: 'auto'
    }}>
      {participants.map((participant) => (
        <ParticipantTile key={participant.identity} participant={participant} />
      ))}
    </div>
  )
}

function ParticipantTile({ participant }: { participant: LocalParticipant | RemoteParticipant }) {
  const videoRef = useRef<HTMLVideoElement>(null)
  const screenRef = useRef<HTMLVideoElement>(null)
  const [hasVideo, setHasVideo] = useState(false)
  const [hasScreen, setHasScreen] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [audioLevel, setAudioLevel] = useState(0)

  useEffect(() => {
    const updateTracks = () => {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–º–µ—Ä—É
      const videoPublication = participant.getTrackPublication(Track.Source.Camera)
      const videoTrack = videoPublication?.track
      
      if (videoTrack && videoRef.current && !videoRef.current.srcObject) {
        videoTrack.attach(videoRef.current)
        setHasVideo(true)
      } else if (!videoTrack) {
        setHasVideo(false)
      } else if (videoTrack) {
        setHasVideo(true)
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º —ç–∫—Ä–∞–Ω—à–∞—Ä–∏–Ω–≥
      const screenPublication = participant.getTrackPublication(Track.Source.ScreenShare)
      const screenTrack = screenPublication?.track
      
      if (screenTrack && screenRef.current) {
        if (screenRef.current.srcObject !== screenTrack.mediaStream) {
          screenTrack.attach(screenRef.current)
        }
        setHasScreen(true)
      } else {
        setHasScreen(false)
      }

      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –¥–ª—è –∏–Ω–¥–∏–∫–∞—Ü–∏–∏
      const audioPublication = participant.getTrackPublication(Track.Source.Microphone)
      if (audioPublication?.track) {
        setupAudioLevelDetection(audioPublication.track as any)
      }
    }

    const setupAudioLevelDetection = (audioTrack: any) => {
      if (!audioTrack.mediaStream) return

      try {
        const audioContext = new AudioContext()
        const source = audioContext.createMediaStreamSource(audioTrack.mediaStream)
        const analyser = audioContext.createAnalyser()
        
        analyser.fftSize = 256
        source.connect(analyser)
        
        const dataArray = new Uint8Array(analyser.frequencyBinCount)
        
        const checkAudioLevel = () => {
          analyser.getByteFrequencyData(dataArray)
          
          // –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–∞
          const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length
          setAudioLevel(average)
          
          // –°—á–∏—Ç–∞–µ–º —á—Ç–æ —á–µ–ª–æ–≤–µ–∫ –≥–æ–≤–æ—Ä–∏—Ç, –µ—Å–ª–∏ —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ 30
          const speaking = average > 30
          setIsSpeaking(speaking)
          
          if (speaking) {
            console.log(`${participant.name || participant.identity} –≥–æ–≤–æ—Ä–∏—Ç (—É—Ä–æ–≤–µ–Ω—å: ${Math.round(average)})`)
          }
        }
        
        const interval = setInterval(checkAudioLevel, 100) // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 100–º—Å
        
        return () => {
          clearInterval(interval)
          audioContext.close()
        }
      } catch (error) {
        console.log('–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é –∑–≤—É–∫–∞:', error)
      }
    }

    // –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–∑—É
    updateTracks()

    // –°–ª—É—à–∞–µ–º —Å–æ–±—ã—Ç–∏—è
    participant.on('trackPublished', updateTracks)
    participant.on('trackUnpublished', updateTracks)
    participant.on('trackSubscribed', updateTracks)
    participant.on('trackUnsubscribed', updateTracks)
    participant.on('trackMuted', updateTracks)
    participant.on('trackUnmuted', updateTracks)

    // –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É
    const interval = setInterval(updateTracks, 1000)

    return () => {
      participant.off('trackPublished', updateTracks)
      participant.off('trackUnpublished', updateTracks)
      participant.off('trackSubscribed', updateTracks)
      participant.off('trackUnsubscribed', updateTracks)
      participant.off('trackMuted', updateTracks)
      participant.off('trackUnmuted', updateTracks)
      clearInterval(interval)
    }
  }, [participant, hasScreen])

  // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–≤–µ—Ç —Ä–∞–º–∫–∏
  const borderColor = isSpeaking ? '#00ff00' : 'transparent'
  const borderWidth = isSpeaking ? '3px' : '1px'

  // –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —ç–∫—Ä–∞–Ω—à–∞—Ä–∏–Ω–≥—É
  if (hasScreen) {
    return (
      <div style={{
        background: '#000',
        borderRadius: '8px',
        overflow: 'hidden',
        position: 'relative',
        minHeight: '300px',
        border: `${borderWidth} solid ${borderColor}`,
        transition: 'border 0.2s ease'
      }}>
        <video
          ref={screenRef}
          autoPlay
          playsInline
          muted={false}
          style={{ width: '100%', height: '100%', objectFit: 'contain' }}
        />
        <div style={{
          position: 'absolute',
          bottom: '8px',
          left: '8px',
          background: 'rgba(0,0,0,0.8)',
          color: 'white',
          padding: '4px 8px',
          borderRadius: '4px',
          fontSize: '0.8rem'
        }}>
          {participant.name || participant.identity} (–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —ç–∫—Ä–∞–Ω–∞)
          {isSpeaking && ' üó£Ô∏è'}
        </div>
      </div>
    )
  }

  return (
    <div style={{
      background: '#222',
      borderRadius: '8px',
      overflow: 'hidden',
      position: 'relative',
      minHeight: '200px',
      display: 'flex',
      alignItems: 'center',
      justifyContent: 'center',
      border: `${borderWidth} solid ${borderColor}`,
      transition: 'border 0.2s ease'
    }}>
      {hasVideo ? (
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted={participant instanceof LocalParticipant}
          style={{ width: '100%', height: '100%', objectFit: 'cover' }}
        />
      ) : (
        <div style={{
          width: '80px',
          height: '80px',
          borderRadius: '50%',
          background: isSpeaking ? '#00aa00' : '#007acc',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          fontSize: '2rem',
          color: 'white',
          transition: 'background 0.2s ease'
        }}>
          {participant.name?.charAt(0).toUpperCase() || 'U'}
        </div>
      )}
      
      <div style={{
        position: 'absolute',
        bottom: '8px',
        left: '8px',
        background: 'rgba(0,0,0,0.7)',
        color: 'white',
        padding: '4px 8px',
        borderRadius: '4px',
        fontSize: '0.8rem'
      }}>
        {participant.name || participant.identity}
        {participant instanceof LocalParticipant ? ' (–≤—ã)' : ''}
        {isSpeaking && ' üó£Ô∏è'}
      </div>
      
      {/* –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞ */}
      {audioLevel > 0 && (
        <div style={{
          position: 'absolute',
          top: '8px',
          right: '8px',
          background: 'rgba(0,255,0,0.7)',
          width: `${Math.min(audioLevel * 2, 100)}px`,
          height: '4px',
          borderRadius: '2px',
          transition: 'width 0.1s ease'
        }} />
      )}
    </div>
  )
}
